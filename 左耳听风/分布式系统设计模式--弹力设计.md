- **容错设计又叫弹力设计**，其中着眼于分布式系统的各种“容忍”能力，包括容错能力（服务隔离、异步调用、请求幂等性）、可伸缩性（有/无状态的服务）、一致性（补偿事务、重试）、应对大流量的能力（熔断、降级）。可以看到，在确保系统正确性的前提下，系统的可用性是弹力设计保障的重点。
- **管理篇**会讲述一些管理分布式系统架构的一些设计模式，比如网关方面的，边车模式，还有一些刚刚开始流行的，如Service Mesh相关的设计模式。
- **性能设计篇**会讲述一些缓存、CQRS、索引表、优先级队列、业务分片等相关的架构模式。

## 弹力设计篇之“认识故障和弹力设计”
[41 弹力设计：认识故障和弹力设计 - 极客时间文档](https://uaxe.github.io/geektime-docs/%E5%90%8E%E7%AB%AF-%E6%9E%B6%E6%9E%84/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/41%20-%20%E5%BC%B9%E5%8A%9B%E8%AE%BE%E8%AE%A1%EF%BC%9A%E8%AE%A4%E8%AF%86%E6%95%85%E9%9A%9C%E5%92%8C%E5%BC%B9%E5%8A%9B%E8%AE%BE%E8%AE%A1/)
### 系统可用性度量
容错设计，在英文中又叫Resiliency（弹力）。意思是，系统在不健康、不顺，甚至出错的情况下有能力hold得住，挺得住，还有能在这种逆境下力挽狂澜的能力。
$$Availability=\frac{MTTF}{MTTF +MTTR}$$
- MTTF 是 Mean Time To Failure，平均故障前的时间，即系统平均能够正常运行多长时间才发生一次故障。系统的可靠性越高，MTTF越长。（注意：从字面上来说，看上去有Failure的字样，但其实是正常运行的时间。）
- MTTR 是 Mean Time To Recovery，平均修复时间，即从故障出现到故障修复的这段时间，这段时间越短越好。
这个公式就是计算系统可用性的，也就是我们常说的，多少个9
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/cbbfa8f48d00644ae2ce70f227b049a6_MD5.jpeg)
提高可用性：要么提高系统的无故障时间，要么减少系统的故障恢复时间

### 故障原因
除了软件设计，还有硬件，还有第三方服务（如电信联通的宽带SLA），当然包括“建筑施工队的挖掘机”。
SLA不只是一个技术指标，还是服务提供商和用户之间的contract，工业界中会把服务不可用的因素分为两种：
**无计划的**
- 系统级故障，包括主机、操作系统、中间件、数据库、网络、电源以及外围设备。
- 数据和中介的故障，包括人员误操作、硬盘故障、数据乱了。
- 还有自然灾害、人为破坏，以及供电问题等。
**有计划的**
- 日常任务：备份，容量规划，用户和安全管理，后台批处理应用。
- 运维相关：数据库维护、应用维护、中间件维护、操作系统维护、网络维护。
- 升级相关：数据库、应用、中间件、操作系统、网络，包括硬件升级。

归类就是：安全问题、性能问题、网络问题、运维问题、管理问题、硬件问题

### 故障不可避免
要意识到：
- 故障是正常的，而且是常见的。
- 故障是不可预测突发的，而且相当难缠。
不要尝试着去避免故障，而是要把处理故障的代码当成正常的功能做在架构里写在代码里。
我们要干的事儿就是想尽一切手段来降低 MTTR——故障的修复时间。
这就是为什么我们把这个设计叫做弹力（Resiliency）。
- 一方面，在好的情况下，这个事对于我们的用户和内部运维来说是完全透明的，系统自动修复不需要人的干预。
- 另一方面，如果修复不了，系统能够做自我保护，而不让事态变糟糕。

## 弹力设计篇之“隔离设计”
[42 弹力设计：隔离设计 - 极客时间文档](https://uaxe.github.io/geektime-docs/%E5%90%8E%E7%AB%AF-%E6%9E%B6%E6%9E%84/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/42%20-%20%E5%BC%B9%E5%8A%9B%E8%AE%BE%E8%AE%A1%EF%BC%9A%E9%9A%94%E7%A6%BB%E8%AE%BE%E8%AE%A1/)
隔离设计对应的单词是 Bulkheads，中文翻译为隔板。
一般来说，对于系统的分离有两种方式，一种是以服务的种类来做分离，一种是以用户来做分离。

### 按服务的种类做分离
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/08d6d457bd5ec035bb613fa24f667d71_MD5.jpeg)
将系统分成了用户、商品、社区三个板块。这三个块分别使用不同的域名、服务器和数据库，做到从接入层到应用层再到数据层三层完全隔离。这样一来，在物理上来说，一个板块的故障就不会影响到另一板块。
Amazon中每个服务都有自己的数据库，每个数据库中都保存着和这个业务相关的数据和相应的处理状态。而每个服务从一开始就准备好了对外暴露。同时，这也是微服务所推荐的架构方式。
存在的问题是：
- 如果我们需要同时获得多个板块的数据，那么就需要调用多个服务，这会降低性能。注意，这里性能降低指的是响应时间，而不是吞吐量（相反，在这种架构下，吞吐量可以得到提高）。
这种情况下，可以通过设计用户交互来解决。
- 如果有大数据平台，就需要把这些数据都抽取到一个数据仓库中进行计算，这也增加了数据合并的复杂度。对于这个问题，我们需要一个框架或是一个中间件来对数据进行相应的抽取。
- 另外，如果我们的业务逻辑或是业务流程需要跨板块的话，那么一个板块的故障也会导致整个流程走不下去，同样会导致整体业务故障。
- 对于这个问题，一方面，我们需要保证这个业务流程中各个子系统的高可用性，并且在业务流程上做成 Step-by-Step 的方式，这样用户交互的每一步都可以保存，以便故障恢复后可以继续执行，而不是从头执行。
- 还有，如果需要有跨板块的交互也会变得有点复杂。对此我们需要一个类似于 Pub/Sub 的高可用、且可以持久化的消息订阅通知中间件来打通各个板块的数据和信息交换。
- 最后还会有在多个板块中分布式事务的问题。对此，我们需要“二阶段提交”这样的方案。在亚马逊中，使用的是 Plan – Reserve – Commit/Cancel 模式。
隔离了的系统需要引入大量的异步处理模型。

### 按用户的请求做分离
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/6918fa2e1e7e6fc70e5e49c1864844d8_MD5.jpeg)
将用户分成不同的组，并把后端的同一个服务根据这些不同的组分成不同的实例。让同一个服务对于不同的用户进行冗余和隔离，这样一来，当服务实例挂掉时，只会影响其中一部分用户，而不会导致所有的用户无法访问。
这种分离可以和按功能的分离进行融合。就是所谓的“多租户”模式。对于一些比较大的客户，我们可以为他们设置专门独立的服务实例，或是服务集群与其他客户隔离开来，对于一些比较小的用户来说，可以让他们共享一个服务实例，这样可以节省相关的资源。
通常来说多租户的做法有三种。
- 完全独立的设计。每个租户有自己完全独立的服务和数据。
- 独立的数据分区，共享的服务。多租户的服务是共享的，但数据是分开隔离的。
- 共享的服务，共享的数据分区。每个租户的数据和服务都是共享的。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/12b308acb5aff2f13a54459222b87e95_MD5.jpeg)
- 如果使用完全独立的方案，在开发实现上和资源隔离度方面会非常好，然而，成本会比较高，计算资源也会有一定的浪费。
- 如果使用完全共享的方案，在资源利用和成本上会非常好，然而，开发难度非常大，而且数据和资源隔离非常不好。
一般来说，技术方案会使用折中方案，也就是中间方案，服务是共享的，数据通过分区来隔离，而对于一些比较重要的租户（需要好的隔离性），则使用完全独立的方式。
在虚拟化技术成熟的今天，我们完全可以使用“完全独立”（完全隔离）的方案，通过底层的虚拟化技术（Hypervisor 的技术，如 KVM，或是 Linux Container 的技术，如 Docker）来实现物理资源的共享和成本的节约。

### 隔离设计的重点
1. 定义隔离业务的大小和粒度
2. 无论是系统板块还是多租户的隔离，需要考虑系统的复杂度、成本、性能以及资源使用情况。
3. 隔离模式需要配置一些高可用、重试、异步、消息中间件，流控、熔断等设计模式的方式配套使用。
4. 需要自动化运维工具
5. 服务监控系统

## 弹力设计篇之“异步通讯设计”
隔离设计需要对系统做解耦设计，把一个单体系统解耦，不单单是把业务功能拆分出来，正如前面所说，拆分完后还会面对很多的问题。其中一个重要的问题就是这些系统间的通讯。
通讯一般来说分同步和异步两种。
同步调用虽然让系统间只耦合于接口，而且实时性也会比异步调用要高，但是我们也需要知道同步调用会带来如下几个问题：
- 同步调用需要被调用方的吞吐不低于调用方的吞吐。否则会被慢的一方拖死，整个同步调用链的性能会由最慢的服务决定
- 同步调用会导致调用方一直在等待被调用方完成，如果一层接一层地同步调用下去，所有的参与方会有相同的等待时间。在并发比较高的场景下，等待会极度消耗资源
- 同步调用只能是一对一的，很难做到一对多。
- 同步调用最不好的是，如果被调用方有问题，那么其调用方就会跟着出问题，于是会出现多米诺骨牌效应，故障一下就蔓延开来。
异步相较于同步来说，可以增加系统的吞吐量，还可以让服务间解耦，统的调用方和被调用方可以按照自己的速率而不是步调一致，从而可以更好地保护系统，让系统更有弹力。

### 异步通讯的三种方式
请求响应式
发送方（sender）会直接请求接收方（receiver），被请求方接收到请求后，直接返回——收到请求，正在处理。
对于返回结果，有两种方法，一种是发送方时不时地去轮询一下，问一下干没干完。另一种方式是发送方注册一个回调方法，也就是接收方处理完后回调请求方。
这种情况下还是有一定耦合的。是发送方依赖于接收方，并且要把自己的回调发送给接收方，处理完后回调。

发布订阅的方式
接收方（receiver）会来订阅发送方（sender）的消息，发送方会把相关的消息或数据放到接收方所订阅的队列中，而接收方会从队列中获取数据。
送方并不关心订阅方的处理结果，它只是告诉订阅方有事要干，收完消息后给个 ACK 就好了，你干成啥样我不关心。
请求响应式的方式有数据状态的往来，所以服务是有状态的。如果我们把服务的状态给去掉（通过第三方的状态服务来保证），那么服务间的依赖就只有事件了。
分布式系统的服务设计是需要向无状态服务（Stateless）努力的，这其中有太多的好处，无状态意味着你可以非常方便地运维。所以，事件通讯成为了异步通讯中最重要的一个设计模式。
在这种方式下，接收方需要向发送方订阅事件，所以是接收方依赖于发送方。这种方式还是有一定的耦合。

通过Broker的方式
所谓 Broker，就是一个中间人，发送方（sender）和接收方（receiver）都互相看不到对方，它们看得到的是一个 Broker，发送方向 Broker 发送消息，接收方向 Broker 订阅消息。如下图所示。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/adb5745595c13d48293435bab91de43b_MD5.jpeg)
这是完全的解耦。所有的服务都不需要相互依赖，而是依赖于一个中间件 Broker。这个 Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。
但是所有人都依赖于一个总线，这个总线需要有如下的特性：
- 必须是高可用的，因为它成了整个系统的关键；
- 必须是高性能而且是可以水平扩展的；
- 必须是可以持久化不丢数据的。

事件驱动设计
发布订阅和通过Broker的方式都是事件驱动架构（EDA – Event Driven Architecture）。
事件驱动最好是使用 Broker 方式，服务间通过交换消息来完成交流和整个流程的驱动。
如下图所示，这是一个订单处理流程。下单服务通知订单服务有订单要处理，而订单服务生成订单后发出通知，库存服务和支付服务得到通知后，一边是占住库存，另一边是让用户支付，等待用户支付完成后通知配送服务进行商品配送。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/380cbe70e19a932fbe978ba787f5a873_MD5.jpeg)
每个服务都是“自包含”的，没有和别人产生依赖。而要把整个流程给串联起来，我们需要一系列的“消息通道（Channel）”。各个服务做完自己的事后，发出相应的事件，而又有一些服务在订阅着某些事件来联动。
事件驱动的好处：
- 服务间的依赖没有了，服务间是平等的，每个服务都是高度可重用并可被替换的。
- 服务的开发、测试、运维，以及故障处理都是高度隔离的。
- 服务间通过事件关联，所以服务间是不会相互 block 的。
- 在服务间增加一些 Adapter（如日志、认证、版本、限流、降级、熔断等）相当容易。
- 服务间的吞吐也被解开了，各个服务可以按照自己的处理速度处理。
事件驱动的缺点是：
- 业务流程不再那么明显和好管理。整个架构变得比较复杂。解决这个问题需要有一些可视化的工具来呈现整体业务流程。
- 事件可能会乱序。这会带来非常 Bug 的事。解决这个问题需要很好地管理一个状态机的控制。
- 事务处理变得复杂。需要使用两阶段提交来做强一致性，或是退缩到最终一致性。

### 异步通讯的设计重点
为什么要异步通讯：
- 异步通讯最重要的是解耦服务间的依赖。最佳解耦的方式是通过 Broker 的机制。
- 解耦的目的是让各个服务的隔离性更好，这样不会出现“一倒倒一片”的故障。
- 异步通讯的架构可以获得更大的吞吐量，而且各个服务间的性能不受干扰相对独立。
- 利用 Broker 或队列的方式还可以达到把抖动的吞吐量变成均匀的吞吐量，这就是所谓的“削峰”，这对后端系统是个不错的保护。
- 服务相对独立，在部署、扩容和运维上都可以做到独立不受其他服务的干扰。
设计异步通讯的时候需要注意：
- 用于异步通讯的中间件 Broker 成为了关键，需要设计成高可用不丢消息的。另外，因为是分布式的，所以可能很难保证消息的顺序，因此你的设计最好不依赖于消息的顺序。
- 异步通讯会导致业务处理流程不那么直观，因为像接力一样，所以在 Broker 上需要有相关的服务消息跟踪机制，否则出现问题后不容易调试。
- 因为服务间只通过消息交互，所以业务状态最好由一个总控方来管理，这个总控方维护一个业务流程的状态变迁逻辑，以便系统发生故障后知道业务处理到了哪一步，从而可以在故障清除后继续处理。
> 	这样的设计常见于银行的对账程序，银行系统会有大量的外部系统通讯，比如跨行的交易、跨企业的交易，等等。所以，为了保证整体数据的一致性，或是避免漏处理及处理错的交易，需要有对账系统，这其实就是那个总控，这也是为什么银行有的交易是 T+1（隔天结算），就是因为要对个账，确保数据是对的。
- 消息传递中，可能有的业务逻辑会有像 TCP 协议那样的 send 和 ACK 机制。比如：A 服务发出一个消息之后，开始等待处理方的 ACK，如果等不到的话，就需要做重传。此时，需要处理方有幂等的处理，即同一条消息无论收到多少次都只处理一次。

### 小结
同步调用的问题：影响吞吐量、消耗系统资源、只能一对一、有多米诺骨牌效应。可以使用异步调用来避免这些问题。
异步调用的方式：请求响应、发布订阅、Broker订阅。

## 弹力设计篇之“幂等性设计”
所谓幂等性设计，就是说，一次和多次请求某一个资源应该具有同样的副作用。
为什么我们需要这样的操作？说白了，就是在我们把系统解耦隔离后，服务间的调用可能会有三个状态，一个是成功（Success），一个是失败（Failed），一个是超时（Timeout）。前两者都是明确的状态，而超时则是完全不知道是什么状态。
因为系统超时，而调用方重试一下，会给我们的系统带来不一致的副作用。
这种情况下，有两种处理方式：
- 一种是需要下游系统提供相应的查询接口。上游系统在 timeout 后去查询一下。如果查到了，就表明已经做了，成功了就不用做了，失败了就走失败流程。
- 另一种是通过幂等性的方式。也就是说，把这个查询操作交给下游系统，我上游系统只管重试，下游系统保证一次和多次的请求结果是一样的。
第一种方式，需要对方提供一个查询接口配合。而第二种方式则需要下游的系统提供支持幂等性的交易接口。

### 全局ID
要做到幂等性的交易接口，需要有一个唯一的标识，来标志交易是同一笔交易。
如果由一个中心系统来分配，那么每一次交易都需要找那个中心系统来。 这样增加了程序的性能开销。如果由上游系统来分配，则可能会出现 ID 分配重复的问题。因为上游系统可能会是一个集群，它们同时承担相同的工作。
为了解决分配冲突问题，需要使用一个不会冲突的算法，比如UUID，但是UUID占用空间大，索引效率低，生成ID太随机，没有可读性，并且不递增，无法排序。
Twitter的Snowflake算法，是一个分布式 ID 的生成算法。它的核心思想是，产生一个 long 型的 ID，其中：
- 41bits 作为毫秒数。大概可以用 69.7 年。
- 10bits 作为机器编号（5bits 是数据中心，5bits 的机器 ID），支持 1024 个实例。
- 12bits 作为毫秒内的序列号。一毫秒可以生成 4096 个序号。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/e9293eadf4b5e61c4a2123bd48f2de19_MD5.jpeg)

### 处理流程
先查后写：
- 收到请求 → 先查存储（数据库/缓存）有没有这个 ID。
- 如果有 → 说明处理过，直接返回之前结果。  
- 如果没有 → 处理请求，并存储 ID。
- ✅ 简单直观，但每次都要查，性能开销大。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/016e676510e64a36109042e19be8193c_MD5.jpeg)
直接写（推荐）：
- 收到请求 → 直接尝试往存储里插入这个 ID。
- 如果成功插入 → 表明是第一次执行，正常处理。
- 如果失败（主键冲突） → 表明已经处理过，直接返回结果。
- ✅ 更快，因为把“查 + 写”合并成一次原子操作。
- 在 MySQL 里可以用 `INSERT ... ON DUPLICATE KEY UPDATE`，或者唯一索引保证。
难点是存储成了单点瓶颈

### HTTP的幂等性
HTTP GET 方法用于获取资源，不应有副作用，所以是幂等的。
HTTP HEAD 和 GET 本质是一样的，区别在于 HEAD 不含有呈现数据，而仅仅是 HTTP 头信息，不应有副作用，也是幂等的。HEAD常常是用于探活使用。
HTTP OPTIONS 主要用于获取当前 URL 所支持的方法，所以也是幂等的。
HTTP DELETE 方法用于删除资源，有副作用，但它应该满足幂等性。
HTTP POST 方法用于创建资源，所对应的 URI 并非创建的资源本身，而是去执行创建动作的操作者，有副作用，不满足幂等性。
HTTP PUT 方法用于创建或更新操作，所对应的 URI 是要创建或更新的资源本身，有副作用，它应该满足幂等性。

所以，对于 POST 的方式，很可能会出现多次提交的问题。一般的幂等性的设计如下：
- 首先，在表单中需要隐藏一个 token，这个 token 可以是前端生成的一个唯一的 ID。用于防止用户多次点击了表单提交按钮，而导致后端收到了多次请求，却不能分辨是否是重复的提交。这个 token 是表单的唯一标识。（这种情况其实是通过前端生成 ID 把 POST 变成了 PUT。）
- 然后，当用户点击提交后，后端会把用户提交的数据和这个 token 保存在数据库中。如果有重复提交，那么数据库中的 token 会做排它限制，从而做到幂等性。
- 当然，更为稳妥的做法是，后端成功后向前端返回 302 跳转，把用户的前端页跳转到 GET 请求，把刚刚 POST 的数据给展示出来。如果是 Web 上的最好还把之前的表单设置成过期，这样用户不能通过浏览器后退按钮来重新提交。这个模式又叫做 PRG 模式（Post/Redirect/Get）。

## 弹力设计篇之“服务的状态”
所谓“状态”，就是为了保留程序的一些数据或是上下文。

### 无状态的服务 Stateless
一直以来，无状态的服务都被当作分布式服务设计的最佳实践和铁律。因为无状态的服务对于扩展性和运维实在是太方便了。
基本上来说，无状态的服务和“函数式编程”的思维方式如出一辙。在函数式编程中，一个铁律是，函数是无状态的。
但是，现实世界是一定会有状态的。这些状态可能表现在如下的几个方面:
- 程序调用的结果
- 服务组合下的上下文
- 服务的配置
为了做出无状态的服务，我们通常需要把状态保存到其他的地方。不重要的存Redis，重要的存MySQL或Zookeeper，Etcd等HA的强一致性存储，或分布式文件系统。
于是，我们为了做成无状态的服务，会导致这些服务需要耦合第三方有状态的存储服务。一方面是有依赖，另一方面也增加了网络开销，导致服务的响应时间也会变慢。
第三方存储服务必须是高可用高拓展的方式。而且，为了减少网络开销，还需要在无状态的服务中增加缓存机制。而用户请求不一定一直在同一台机器，这会导致所有实例都会存储缓存。
这种“转移责任”的玩法也催生出了对分布式存储的强烈需求。因为数据层的scheme很多，所以做出一个通用的分布式存储系统很难。
这也是为什么无状态的服务需要依赖于像 ZooKeeper/Etcd 这样的高可用的有强一致的服务，或是依赖于底层的分布式文件系统（像开源的 Ceph 和 GlusterFS）。而现在分布式数据库也开始将服务和存储分离，也是为了让自己的系统更有弹力。

### 有状态的服务 Stateful
无状态服务在程序 Bug 上和水平扩展上有非常优秀的表现，但是其需要把状态存放在一个第三方存储上，增加了网络开销，而在服务内的缓存需要在所有的服务实例上都有（因为每次请求不会都落在同一个服务实例上），这是比较浪费资源的。
有状态服务的好处是：
- 数据本地化Data Locality；一方面状态和数据是本机保存，这方面不但有更低的延时，而且对于数据密集型的应用来说，这会更快。
- 更高的可用性和更强的一致性。CAP中的AC
因为对于有状态的服务，我们需要对于客户端传来的请求，都必须保证其落在同一个实例上，这叫 Sticky Session 或是 Sticky Connection。
无状态的服务需要我们把数据同步到不同的节点上，而有状态的服务通过 Sticky Session 做数据分片（当然，同步有同步的问题，分片也有分片的问题，这两者没有谁比谁好，都有 trade-off）。

Sticky Session是怎么实现的呢？
(1) **长连接**
如果客户端和某个后端建立了长连接（例如 WebSocket、HTTP/2、gRPC），那么只要连接不断开，所有请求都会走同一个节点。
简单粗暴，但容易产生 **热点问题**：某些节点连接太多，压力过大。
解决方式之一是 **反向压力**：当节点过载时，主动断开部分连接，让客户端重新连接其他节点。但这种方式需要客户端配合（能正确重试、重新路由），否则容易出 bug。
(2) **哈希（Hash）路由**
通过某个字段（如 `uid`、`sessionId`）做一致性哈希
负载不均衡（哈希结果不一定均匀）。
(3) **元数据索引 + 路由节点**
引入一个 **路由层**（像注册中心/调度器），维护 **元数据索引表**，记录「用户 → 服务节点」的映射。
路由层成为中心化组件，可能成为瓶颈或单点故障。
(4) **Gossip 协议（去中心化）**
不要一个「中心路由层」，而是 **各个节点之间互相同步元数据索引**。去中心化，避免单点瓶颈。
实现复杂，尤其是要保证一致性和快速收敛。

### 服务状态的容错设计
在容错设计中，服务状态是一件非常复杂的事。尤其对于运维来说，因为你要调度服务就需要调度服务的状态，迁移服务的状态就需要迁移服务的数据。在数据量比较大的情况下，这一点就变得更为困难了。
虽然上述有状态的服务的调度通过 Sticky Session 的方式是一种方式，但实际上很麻烦。
很多系统的高可用的设计都会采取数据在运行时就复制的方案，比如：ZooKeeper、Kafka、Redis 或是 ElasticSearch 等等。在运行时进行数据复制就需要考虑一致性的问题，所以，强一致性的系统一般会使用两阶段提交。
这需要所有节点需要有一致的结果，就是CAP中的CA系统；有的系统是大多数一致，Paxos就是CP系统。
所以需要用到DFS，把状态放到 **分布式文件系统**，服务实例只是“挂载和使用”它。这样节点挂掉 → 新节点启动 → 直接加载数据卷 → 快速恢复。
==使用一个分布式文件系统是调度有状态服务的关键。==

## 弹力设计篇之“补偿事务”
分布式系统有一个比较明显的问题就是，一个业务流程需要组合一组服务。如果一个步骤失败了，那么要么回滚到以前的服务调用，要么不断重试保证所有的步骤都成功。
如果需要强一致性，那在业务层上就需要使用“两阶段提交”这样的方式。但是好在我们的很多情况下并不需要这么强的一致性，而且强一致性的最佳保证基本都是在底层完成的，或是像之前说的那样 Stateful 的 Sticky Session 那样在一台机器上完成。在我们接触到的大多数业务中，其实只需要最终一致性就够了。

### ACID和BASE
传统关系型数据库系统的事务都有 ACID 属性，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。
但是这种方式对于分布式系统很难满足高性能的要求。为了提高性能，出现了 ACID 的一个变种 BASE：
- Basic Availability：基本可用。这意味着，系统可以出现暂时不可用的状态，而后面会快速恢复。
- Soft-state：软状态。它是我们前面的“有状态”和“无状态”的服务的一种中间状态。也就是说，为了提高性能，我们可以让服务暂时保存一些状态或数据，这些状态和数据不是强一致性的。
- Eventual Consistency：最终一致性，系统在一个短暂的时间段内是不一致的，但最终整个系统看到的数据是一致的。
BASE 系统是允许或是容忍系统出现暂时性问题的，故障不可避免，需要Design for Failure。
BASE 的系统倾向于设计出更加有弹力的系统，这种系统的设计特点是，要保证在短时间内，就算是有数据不同步的风险，我们也应该允许新的交易可以发生，而后面我们在业务上将可能出现问题的事务给处理掉，以保证最终的一致性。
ACID 的意思是酸，而 BASE 却是碱的意思，因此这是一个对立的东西。其实，从本质上来讲，酸（ACID）强调的是一致性（CAP 中的 C），而碱（BASE）强调的是可用性（CAP 中的 A）。

### 业务补偿
在很多情况下，我们是无法做到强一致的 ACID 的。
当业务过程中，条件不满足，或是有变化的时候，需要从业务上做相应的整体事务的补偿。
一般来说，业务的事务补偿都是需要一个工作流引擎的。
对于业务补偿来说，首先需要将服务做成幂等性的，如果一个事务失败了或是超时了，我们需要不断地重试，努力地达到最终我们想要的状态。然后，如果我们不能达到这个我们想要的状态，我们需要把整个状态恢复到之前的状态。另外，如果有变化的请求，我们需要启动整个事务的业务更新机制。

一个好的业务补偿机制：
1. 要能清楚地描述出要达到什么样的状态，以及如果其中的条件不满足，那么，我们要回退到哪一个状态。这就是所谓的整个业务的起始状态定义。
2. 当整条业务跑起来的时候，我们可以串行或并行地做这些事。我们的系统需要努力地通过一系列的操作达到一个我们想要的状态。如果达不到，就需要通过补偿机制回滚到之前的状态。这就是所谓的状态拟合。
3. 对于已经完成的事务进行整体修改，可以考虑成一个修改事务。

### 业务补偿的设计重点
1. 努力地把一个业务流程执行完成。
2. 如果执行不下去，需要启动补偿机制，回滚业务流程。
重点：
- 服务方支持幂等性，在上游有重试机制。
- 维护和监控整个过程的状态，最好是一个业务流程的控制方来做这个事，也就是一个工作流引擎。
- 补偿的业务逻辑和流程不一定非得是严格反向操作。
- 业务补偿的业务逻辑是强业务相关的，很难做成通用的。
- 下层的业务方最好提供短期的资源预留机制。

### 小结
分布式系统中，ACID有更强的一致性，但可伸缩性很差；BASE的一致性较弱，有很好的伸缩性，可以异步批量处理；大多数分布式事务适合BASE。
要实现 BASE 事务，需要实现补偿逻辑，因为事务可能失败，此时需要协调各方进行撤销。补偿的各个步骤可以根据具体业务来确定是串行还是并行。由于补偿事务是和业务强相关的，所以必须实现在业务逻辑里。

## 弹力设计篇之“重试设计”
单体应用服务化，就将一个进程内的函数调用变成了远程调用，涉及到网络上的问题。但是网络设备不是稳定的，所以需要重试。

### 重试的场景
“重试”的语义是我们认为这个故障是暂时的，而不是永久的，所以，我们会去重试。

### 重试的策略
都需要有个重试的最大值，经过一段时间不断的重试后，就没有必要再重试了，应该报故障了。在重试过程中，每一次重试失败时都应该休息一会儿再重试，这样可以避免因为重试过快而导致网络上的负担加重。
重试的设计中，一般会引入Exponential Backoff 的策略，也就是所谓的“指数级退避”。与TCP拥塞控制相似。

### Spring的重试策略
Spring Retry 是一个单独实现重试功能的项目，我们可以通过 Annotation 的方式使用。
```java
@Service
public interface MyService {
	@Retryable(
	value = { SQLException.class },
	maxAttempts = 2,
	backoff = @Backoff(delay = 5000))
	void retryService(String sql) throws SQLException;
		...
	}
```
配置 @Retryable 注解，只对 SQLException 的异常进行重试，重试两次，每次延时 5000ms。
Spring的重试策略有：
- NeverRetryPolicy：只允许调用 RetryCallback 一次，不允许重试。
- AlwaysRetryPolicy：允许无限重试，直到成功，此方式逻辑不当会导致死循环。
- SimpleRetryPolicy：固定次数重试策略，默认重试最大次数为 3 次，RetryTemplate 默认使用的策略。
- TimeoutRetryPolicy：超时时间重试策略，默认超时时间为 1 秒，在指定的超时时间内允许重试。
- CircuitBreakerRetryPolicy：有熔断功能的重试策略，需设置 3 个参数 openTimeout、resetTimeout 和 delegate；关于熔断，会在后面描述。
- CompositeRetryPolicy：组合重试策略。有两种组合方式，乐观组合重试策略是指只要有一个策略允许重试即可以，悲观组合重试策略是指只要有一个策略不允许重试即不可以。但不管哪种组合方式，组合中的每一个策略都会执行。
关于Backoff的策略如下：
- NoBackOffPolicy：无退避算法策略，即当重试时是立即重试；
- FixedBackOffPolicy：固定时间的退避策略，需设置参数 sleeper 和 backOffPeriod，sleeper 指定等待策略，默认是 Thread.sleep，即线程休眠，backOffPeriod 指定休眠时间，默认 1 秒。
- UniformRandomBackOffPolicy：随机时间退避策略，需设置 sleeper、minBackOffPeriod 和 maxBackOffPeriod。该策略在\[minBackOffPeriod, maxBackOffPeriod]之间取一个随机休眠时间，minBackOffPeriod 默认为 500 毫秒，maxBackOffPeriod 默认为 1500 毫秒。
- ExponentialBackOffPolicy：指数退避策略，需设置参数 sleeper、initialInterval、maxInterval 和 multiplier。initialInterval 指定初始休眠时间，默认为 100 毫秒。maxInterval 指定最大休眠时间，默认为 30 秒。multiplier 指定乘数，即下一次休眠时间为当前休眠时间 *multiplier。
- ExponentialRandomBackOffPolicy：随机指数退避策略，引入随机乘数，之前说过固定乘数可能会引起很多服务同时重试导致 DDos，使用随机休眠时间来避免这种情况。

### 重试设计的重点
要确定什么样的错误下需要重试；
重试的时间和重试的次数。这种在不同的情况下要有不同的考量。有时候，面对一些不是很重要的问题时，我们应该更快失败而不是重试一段时间若干次。比如一个前端的交互需要用到后端的服务。这种情况下，在面对错误的时候，应该快速失败报错（比如：网络错误请重试）。而面对其它的一些错误，比如流控，那么应该使用指数退避的方式，以避免造成更多的流量。
如果超过重试次数，或是一段时间，那么重试就没有意义了。这个时候，说明这个错误不是一个短暂的错误，那么我们对于新来的请求，就没有必要再进行重试了，这个时候对新的请求直接返回错误就好了。但是，这样一来，如果后端恢复了，我们怎么知道呢，此时需要使用我们的熔断设计了。
重试还需要考虑被调用方是否有幂等的设计。如果没有，那么重试是不安全的，可能会导致一个相同的操作被执行多次。
重试的代码比较简单也比较通用，完全可以不用侵入到业务代码中。这里有两个模式。一个是代码级的，像 Java 那样可以使用 Annotation 的方式（在 Spring 中你可以用到这样的注解），如果没有注解也可以包装在底层库或是 SDK 库中不需要让上层业务感知到。另外一种是走 Service Mesh 的方式
对于有事务相关的操作。我们可能会希望能重试成功，而不至于走业务补偿那样的复杂的回退流程。对此，我们可能需要一个比较长的时间来做重试，但是我们需要保存请求的上下文，这可能对程序的运行有比较大的开销，因此，有一些设计会先把这样的上下文暂存在本机或是数据库中，然后腾出资源来做别的事，过一会再回来把之前的请求从存储中捞出来重试。

## 弹力设计篇之“熔断设计”
防止某个依赖服务持续故障时，大量请求继续打过去，把故障放大（雪崩效应）。
当检测到失败率过高时，短路调用，快速失败，保护系统；等一段时间后，再尝试恢复调用。
### 熔断设计
熔断器模式可以防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费 CPU 时间去等待长时间的超时产生。熔断器模式也可以使应用程序能够诊断错误是否已经修正。如果已经修正，应用程序会再次尝试调用操作。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/3fccb5d1f8955d3ce024b117beab4044_MD5.jpeg)
熔断器可以使用状态机来实现，内部模拟以下几种状态：
- 闭合（Closed）状态：所有请求都正常发往目标服。统计失败次数或失败率，如果超过阈值，就进入 **断开（Open）** 状态。
- 断开 (Open) 状态：请求**不会再发给目标服务**，而是直接返回错误（或者返回缓存的旧数据）。开启超时计时器，超时时间到了，就进入 **半开（Half-Open）** 状态。
- 半开（Half-Open）状态：允许**少量测试请求**通过（比如每秒 1 个请求），相当于探测目标服务是否恢复。如果这些请求**成功率很高**，说明服务恢复了 → 切换回 **闭合（Closed）**。如果这些请求还是失败 → 切回 **断开（Open）**，重新等待一段时间再尝试。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/420e856c5e3c724e6d6ac68a2fecb7cd_MD5.jpeg)
下图是netflix的Hystrix中的熔断实现逻辑
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/b4781fc2d851ff1624b804a3a70d23eb_MD5.jpeg)
> Hystrix:
> 防止单个服务调用失败，导致级联故障，保护整个系统的稳定性。
> 2018 年后进入维护模式，Netflix 官方推荐迁移到 **resilience4j**
> Hystrix提供以下能力：
> 熔断器：Closed、Open、Half-Open状态机，根据失败率阈值自动切换状态
> 隔离：使用线程池隔离或信号量隔离
> 	- **线程池隔离**：每个服务调用用独立的线程池执行，避免某个服务卡死拖垮整个系统。
> 	- **信号量隔离**：用信号量控制并发数，轻量但不支持超时控制。
> 降级：调用失败或熔断，执行备用逻辑
> 限流：通过线程池或信号量限制并发调用量
> 超时控制：每次调用都有最大等待时间，超时终端走Fallback
> 监控：提供实时监控指标

### 熔断设计的重点
- 错误的类型。熔断和重试一样，需要对返回的错误进行识别。
- 日志监控。熔断器记录所有失败的请求，以及一些可能会尝试成功的请求
- 测试服务是否可用。定期ping远程服务的健康检查接口。
- 手动重置。提供手动重置功能使得管理员可以手动将熔断器切换到闭合
- 并发问题。熔断器的实现不应该阻塞并发的请求或者增加每次请求调用的负担。
- 资源分区。把资源分布在不同的分区上。
- 重试错误的请求。

## 弹力设计篇之“限流设计”
保护系统不会在过载的情况下出现问题，需要进行限流。

### 限流的策略
限流的目的是通过对并发访问进行限速，相关的策略一般是，一旦达到限制的速率，那么就会触发相应的限流行为。触发的限流行为如下：
- 拒绝服务。把多出来的请求拒绝掉。一般会统计当前哪个客户端来的请求最多，拒掉这个客户端。
- 服务降级。关闭或是把后端服务做降级处理。这样可以让服务有足够的资源来处理更多的请求。降级有很多方式，一种是把一些不重要的服务给停掉，把 CPU、内存或是数据的资源让给更重要的功能；一种是不再返回全量数据，只返回部分数据。
- 特权请求。资源不够了，我只能把有限的资源分给重要的用户
- 延迟处理。队列来缓冲大量的请求，这个队列如果满了，那么就只能拒绝用户了，如果这个队列中的任务超时了，也要返回系统繁忙的错误了。使用缓冲队列只是为了减缓压力，一般用于应对短暂的峰刺请求。
- 弹性伸缩。动用自动化运维的方式对相应的服务做自动化的伸缩。

### 限流的实现方式
计数器方式
维护一个计数器 Counter，当一个请求来时，就做加一操作，当一个请求处理完后就做减一操作。如果这个 Counter 大于某个数了（我们设定的限流阈值），那么就开始拒绝请求以保护系统的负载了。

队列算法
请求的速度可以是波动的，而处理的速度则是非常均速的。这个算法其实有点像一个 FIFO 的算法。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/1cfa0fd42f4c01aea3e7380f733e2c71_MD5.jpeg)
可以进行适当的改进：
有优先级的队列，处理时先处理高优先级的队列，然后再处理低优先级的队列。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/114dd85b46c6ce9924f5d66e746f196f_MD5.jpeg)
有优先级的队列可能会导致低优先级队列长时间得不到处理。为了避免低优先级的队列被饿死，一般来说是分配不同比例的处理时间到不同的队列上，于是我们有了带权重的队列。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/19a87dda7eb4a54e27e39aa9fb8f15ed_MD5.jpeg)
队列流控是以队列的方式来处理请求。如果处理过慢，那么就会导致队列满，而开始触发限流。
这样的算法需要用队列长度来控制流量，在配置上比较难操作。如果队列过长，导致后端服务在队列没有满时就挂掉了。一般来说，这样的模型不能做 push，而是 pull 方式会好一些。

漏斗算法Leaky Bucket
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/ecdcabda9f888d93d5b3a1e4a216efb5_MD5.jpeg)
这个“漏斗”是用一个队列来实现的，当请求过多时，队列就会开始积压请求，如果队列满了，就会开始拒绝请求。
漏斗算法其实就是在队列请求中加上一个限流器，来让 Processor 以一个均匀的速度处理请求。

令牌桶算法Token Bucket
令牌桶算法，主要是有一个中间人。在一个桶内按照一定的速率放入一些 token，然后，处理程序要处理请求时，需要拿到 token，才能处理；如果拿不到，则不处理。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/7cfda7741856a3ce83be98f2cc5e371f_MD5.jpeg)
从理论上来说，令牌桶的算法和漏斗算法不一样的是，漏斗算法中，处理请求是以一个常量和恒定的速度处理的，而令牌桶算法则是在流量小的时候“攒钱”，流量大的时候，可以快速处理。

|特性|Leaky Bucket（漏桶）|Token Bucket（令牌桶）|
|---|---|---|
|控制方式|请求先排队再均匀处理|请求必须拿到令牌才能执行|
|输出速率|固定、平滑|平均受控，但可突发|
|是否支持突发流量|❌ 不支持|✅ 支持|
|请求丢弃时机|桶满时丢弃|无令牌时丢弃|
|应用场景|网络整形、严格限速|API 限流、突发流量控制|

基于响应时间的动态限流
上面的算法有个不好的地方，就是需要设置一个确定的限流值。这就要求我们每次发布服务时都做相应的性能测试，找到系统最大的性能值。
但性能测试不是容易做的。
在很多时候，我们却并不知道这个限流值，或是很难给出一个合适的值。其基本会有如下的一些因素：
- 实际情况下，很多服务会依赖于数据库。所以，不同的用户请求，会对不同的数据集进行操作。就算是相同的请求，可能数据集也不一样
- 不同的 API 有不同的性能。我们要在线上为每一个 API 配置不同的限流值，这点太难配置，也很难管理。
- 现在的服务都是能自动化伸缩的，不同大小的集群的性能也不一样，所以，在自动化伸缩的情况下，我们要动态地调整限流的阈值

==限流的值很难被设置为一个固定的值==
使用动态限流的方式，动态感知系统的压力自动化限流。
这方面设计的典范是 TCP 协议的拥塞控制的算法。TCP 使用 RTT - Round Trip Time 来探测网络的延时和性能，从而设定相应的“滑动窗口”的大小，以让发送的速率和网络的性能相匹配。
记录下每次调用后端请求的响应时间，然后在一个时间区间内（比如，过去 10 秒）的请求计算一个响应时间的 P90 或 P99 值，也就是把过去 10 秒内的请求的响应时间排个序，然后看 90% 或 99% 的位置是多少。
如果这个 P90 或 P99 超过我们设定的阈值，那么我们就自动限流。
设计重点：
- 你需要计算的一定时间内的 P90 或 P99。在有大量请求的情况下，这个非常地耗内存也非常地耗 CPU，因为需要对大量的数据进行排序。
解决方法：一是采样，二是使用蓄水池的近似算法
- 动态流控需要像 TCP 那样，你需要记录一个当前的 QPS。如果发现后端的 P90/P99 响应太慢，那么就可以把这个 QPS 减半，然后像 TCP 一样走慢启动的方式。如果后端扩容伸缩后性能变好，系统会自动适应后端的最大性能。

> 蓄水池思想：
> [蓄水池采样算法（Reservoir Sampling）原理，证明和代码-CSDN博客](https://blog.csdn.net/anshuai_aw1/article/details/88750673)
> 在流量不可预知、且数据流规模很大（甚至无限）的情况下，从所有请求中**近似均匀随机**地保留一小部分（k 个）。
> 假设需要采样的数量为 k 。
> 首先构建一个可容纳 k 个元素的数组，将序列的前 k 个元素放入数组中。
> 然后对于第 j （j > k）个元素开始，以 k/j ​的概率来决定该元素是否被替换到数组中（数组中的k个元素被替换的概率是相同的）。 当遍历完所有元素之后，数组中剩下的元素即为所需采取的样本。

### 限流的设计要点
目的是：
1. 向用户承诺SLA。系统的响应时间和可用性
2. 阻止在多租户的情况下，某一用户把资源耗尽
3. 应对突发流量
4. 节约成本。我们不会为了一个不常见的尖峰来把我们的系统扩容到最大的尺寸。而是在有限的资源下能够承受比较高的流量。
设计上的考量：
- 限流应该是在架构的早期考虑。当架构形成后，限流不是很容易加入。
- 限流模块必须性能好，对流量的变化敏感。
- 有手动开关
- 监控时间通知
- 当限流发生时，对于拒掉的请求，我们应该返回一个特定的限流错误码。
- 限流应该让后端的服务感知到。后端根据表示决定是否降级

## 弹力设计篇之“降级设计”
降级设计（Degradation），本质是为了解决资源不足和访问量过大的问题。当资源和访问量出现矛盾的时候，在有限的资源下，为了能够扛住大量的请求，我们就需要对系统进行降级操作。也就是说，暂时牺牲掉一些东西，以保障整个系统的平稳运行。
降级需要牺牲掉的东西：
- 降低一致性：强一致性变成最终一致性
- 停掉次要功能。释放更多的资源
- 简化功能。简化业务流程，不返回全量数据，返回部分数据

### 降低一致性
降低一致性可以有效的释放资源，使得系统运行的更快，抗住更大的流量。两种做法：一种是简化流程的一致性，一种是降低数据的一致性。

### 使用异步简化流程
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/93551c80d44c3f8eca2ce8bdf4fef432_MD5.jpeg)
一开始需要的全同步的方式，降级成了全异步的方式，库存从单笔强一致性也变成了多笔最终一致性，如果库存不够了，就只能根据先来后到取消订单了。而支付也从最开始的下单请求时的强一致性，变成了用户到付的最终一致性。
功能降级都有可能会损害用户的体验，所以，最好给出友好的用户提示。比如，“系统当前繁忙，您的订单已收到，我们正努力为您处理订单中，我们会尽快给您发送订单确认通知……还请见谅”诸如此类的提示信息。

### 降低数据的一致性
降低数据的一致性一般来说会使用缓存的方式，或是直接就去掉数据。

> 缓存的更新策略
> - Cache Aside旁路缓存 ==最常见==
> 读：应用先查缓存，缓存miss，应用查数据库，结果写入缓存
> 写：先写数据库，再删除缓存
> 适合读多写少，允许短时间缓存不一致
> - Read Through读穿透
> 读：应用只访问缓存，缓存miss，缓存自己查数据库并写入
> 写：可配合Write Through或Cache Aside策略
> 适合通用的缓存中间件Caffeine
> - Write Through写穿透
> 读：通常是Read Through策略
> 写：应用写缓存，缓存同步写数据库
> 适合数据一致性要求高，写请求不多的系统
> - Write Back/Write Behind异步写回
> 写：应用只写缓存，不写数据库；缓存异步、批量刷新到数据库
> 适合写入频繁，允许延迟落库
> - Refresh Ahead提前刷新
> 缓存过期前，异步刷新缓存，使得热点数据始终在缓存中
> 适合热点数据明显，读性能高

Cache Aside写操作是删除缓存而不是更新缓存：防止两个并发的写操作会导致脏数据
解决办法就是通过2PC或Paxos协议保证一致性，要么是降低并发时脏数据的概率。所以最好给缓存设置过期时间。
Write Behind，也是Write Back。与Linux文件系统的Page Cache算法一样，问题就是数据不是强一致性的，可能会丢失。

|策略|优点|缺点|典型场景|
|---|---|---|---|
|Cache Aside|简单，读性能高|写后可能不一致|电商详情、用户信息|
|Read Through|应用逻辑简单|缓存要会查DB|内存缓存框架|
|Write Through|数据一致性好|写性能差|配置中心、计费系统|
|Write Back|写吞吐高|容易丢数据|日志系统、计数器|
|Refresh Ahead|热点命中率高|需要预测热点|热点榜单、推荐系统|

|对比点|Read Through|Write Through|
|---|---|---|
|关注点|**读**操作的缓存缺失时谁来加载数据|**写**操作时谁来更新数据库|
|流程|miss 时缓存自己去查 DB 并回填|应用写缓存 → 缓存写 DB|
|应用是否接触 DB|读时应用不直接接触 DB|写时应用不直接接触 DB|
|优点|应用逻辑更简单，读一致性好|保证缓存和 DB 强一致|
|缺点|缓存实现要有 DB 访问能力|写性能较差（写两份）|
|常用场景|本地缓存框架（Guava/Ehcache）|配置中心、金融账本|

对于缓存来说，可以有效地降低数据库的压力，把数据库的资源交给更重要的业务，这样就能让系统更快速地运行。
对于降级后的系统，不再通过数据库获取数据，而是通过缓存获取数据。
在功能降级中，我们一般使用 Cache Aside 模式或是 Read Through 模式。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/48564c005ad2e730059f7312e4ac8b82_MD5.jpeg)
Read Through 模式就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或 LRU 换出），Cache Aside 是由调用方负责把数据加载到缓存，而 Read Through 则用缓存服务自己来加载，从而对应用方是透明的。

### 停止次要的功能
停止次要的功能，系统释放出更多的资源。
当然，最好不要停止次要的功能，首先可以限制次要的功能的流量，或是把次要的功能退化成简单的功能，最后如果量太大了，我们才会进入停止功能的状态。

### 简化功能
一般来说，一个 API 会有两个版本，一个版本返回全量数据，另一个版本只返回部分或最小的可用的数据。

### 降级设计的要点
对于降级，一般来说是要牺牲业务功能或是流程，以及一致性的。所以，我们需要对业务做非常仔细的梳理和分析。我们很难通过不侵入业务的方式来做到功能降级。
在设计降级的时候，需要清楚地定义好降级的关键条件，比如，吞吐量过大、响应时间过慢、失败次数过多，有网络或是服务故障，等等，然后做好相应的应急预案。这些预案最好是写成代码可以快速地自动化或半自动化执行的。
功能降级需要梳理业务的功能，哪些是 must-have 的功能，哪些是 nice-to-have 的功能；哪些是必须要死保的功能，哪些是可以牺牲的功能。而且需要在事前设计好可以简化的或是用来应急的业务流程。当系统出问题的时候，就需要走简化应急流程。
降级的时候，需要牺牲掉一致性，或是一些业务流程：对于读操作来说，使用缓存来解决，对于写操作来说，需要异步调用来解决。
降级的功能的开关可以是一个系统的配置开关。做成配置时，你需要在要降级的时候推送相应的配置。另一种方式是，在对外服务的 API 上有所区分（方法签名或是开关参数），这样可以由上游调用者来驱动。

## 弹力设计篇之“弹力设计总结”
### 弹力设计总图
首先服务不能是单点，所以需要在架构中冗余服务，也就是多副本。
	负载均衡 + 服务健康检查–可以使用像 Nginx 或 HAProxy 这样的技术；
	服务发现 + 动态路由 + 服务健康检查，比如 Consul 或 ZooKeeper；
	自动化运维，Kubernetes 服务调度、伸缩和故障迁移。
然后需要隔离业务，也就是对服务进行解耦和拆分。
	bulkheads 模式：业务分片 、用户分片、数据库拆分。
	自包含系统：所谓自包含的系统是从单体到微服务的中间状态，其把一组密切相关的微服务给拆分出来，只需要做到没有外部依赖就行。
	异步通讯：服务发现、事件驱动、消息队列、业务工作流。
	自动化运维：需要一个服务调用链和性能监控的监控系统。
最后就是容错设计。
	错误方面：调用重试 + 熔断 + 服务的幂等性设计。
	一致性方面：强一致性使用两阶段提交、最终一致性使用异步通讯方式。
	流控方面：使用限流 + 降级技术。
	自动化运维方面：网关流量调度，服务监控。
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/d72019a80aa9ba812e58ef437abe30b8_MD5.jpeg)
总共三大块内容：
冗余服务。通过冗余服务的复本数可以消除单点故障。这需要服务发现，负载均衡，动态路由和健康检查四个功能或组件。
服务解耦。通过解耦可以做到把业务隔离开来，不让服务受影响，这样就可以有更好的稳定性。在水平层面上，需要把业务或用户分片分区（业分做隔离，用户做多租户）。在垂直层面上，需要异步通讯机制。因为应用被分解成了一个一个的服务，所以在服务的编排和聚合上，需要有工作流（像 Spring 的 Stream 或 Akka 的 flow 或是 AWS 的 Simple Workflow）来把服务给串联起来。而一致性的问题又需要业务补偿机制来做反向交易。
服务容错。服务容错方面，需要有重试机制，重试机制会带来幂等操作，对于服务保护来说，熔断，限流，降级都是为了保护整个系统的稳定性，并在可用性和一致性方面在出错的情况下做一部分的妥协。

除了以上这些，还需要自动化运维工具。

### 弹力设计开发和运维
至少需要两个系统：
- 类似APM服务进啊空
- 服务调度系统，如Docker+K8S
![](%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/attachments/bf2ea00b31002c04660878be9a73549e_MD5.jpeg)
目前都是遵循Spring Cloud规范+K8S做出一个可运维的分布式系统。